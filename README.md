
<p align="center" width="100%">
<img src="assets/logo1.png" alt="Guanaco" style="width: 90%; min-width: 300px; display: block; margin: auto;">
</p>

# Guanaco: Seeding, Tuning, Generating, and the problem of critical intervention in Large Language Models

The third animal that follows the pair llama and alpaca is guanaco.

This is the code repository for the 'Guanaco' lesson plan contained in *Peripheral: teaching digital cultures in chaotic times*, published by *The Institute of Network Cultures*. Follow along with the lesson via the journal: *link TBC*.

Note: Guanaco is a hypothetical AI model for research and educational purposes.

## Overview

In February 2023 Meta released LLaMA, a set of large language models trained on billions of parameters. In March 2023 Stanford University researchers released [Alpaca](https://github.com/tatsu-lab/stanford_alpaca), a model of LLaMA fine-tuned on a synthetic dataset of 52,000 instruction parameters which had been generated by ChatGPT3 from 175 human-written instructions. Both the 175 human instructions and the 52 thousand generated parameters are publicly available on the [research team’s github](https://github.com/tatsu-lab/stanford_alpaca). The Stanford team’s raison d’être for the project was to provide a way of encouraging researchers to develop models which would overcome known ‘deficiencies’ in generative AI, especially the tendency to “generate false information, propagate social stereotypes, and produce toxic language”. 

Days later however, the live model was taken down due to ‘safety issues’ — despite its enlightened origins, the model displayed a noted tendency towards ‘hallucinating’ falsehoods and the production of ‘[offensive text](https://www.theregister.com/2023/03/21/stanford_ai_alpaca_taken_offline/)’.

The question is — why then did Alpaca fail, and what is it to ‘fine-tune’ an AI model? Thao Phan and Fabian Offert have criticised some recent efforts to ‘debias’ generative AI models as superficial, as failing especially to confront “the consistent reproduction of whiteness as a latent feature of dominant…culture” ([2022](https://arxiv.org/abs/2211.06323)). To what extent can a model be ‘tuned’ beyond or outside or against its foundational parameters and weightings? 

The lesson proposed [here](https://networkcultures.org) takes two steps. In the first the classroom will be invited to compare Alpaca’s 175 human instructions with the 52,000 GPT3-generated instruction parameters — how do categories of race, gender, sexuality and the political appear differently in the human generated and machine generated prompts? What does this difference reveal about the way the LLM transforms human intentionality, desires, and political engagements?

The second part of the lesson will be to generate a new AI model within the camelid family, Guanaco. After reflecting on a series of critical AI texts, the classroom will collectively devise their own AI model by manually writing 175 original seed tasks, with ideas of race, gender, sexuality and the political front of mind. GPT3.5 is then prompted to generate an additional thousand tasks based on the seed-set created within the classroom.

Students will be asked to reflect upon the relation between seed, generation, and hallucination. To what degree is political intervention possible in large language models? To what degree can experiments in tuning make present and detourn models’ foundations, and what consequences do such experiments have in a chaotic age of increasingly accessible and normalised access to generative AI?

## Lesson Plan

Note: The full lesson plan is featured in *Peripheral*: *link TBC*

### Step one:

Compare the [175 seed tasks](./alpaca_seed_tasks.jsonl) with the [52,000 GPT3-generated instruction parameters](./alpaca_generated_data.json).

#### Key texts:
- Stanford Alpaca's release [blog post](https://crfm.stanford.edu/2023/03/13/alpaca.html).
- The [Self-Instruct paper](https://arxiv.org/abs/2212.10560) by Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, Hannaneh Hajishirzi. 

### Step two: creating Guanaco

As a class, manually write your own [175 original seed tasks](./guanaco_seed_tasks.jsonl).

#### Key reading:
- [A Sign That Spells](https://arxiv.org/abs/2211.06323) by Fabian Offert and Thao Phan.

To generate a synthetic dataset from your original seed tasks please follow the steps outlined below.

### Data Generation Process

This data generation pipeline was built by the [Stanford Alpaca](https://github.com/tatsu-lab/stanford_alpaca) team, on top of the framework designed by for [self-instruct](https://github.com/yizhongw/self-instruct).

Ensure you have Python installed on your computer before starting.

<details>
<summary> 1. Downloading the Code Repository from GitHub</summary>
- Navigate to the GitHub Page: Open your web browser and go to the GitHub page where the code repository is located.
- Download the Repository: Look for a green button labeled "Code" near the top of the page. Click on it and then select "Download ZIP" from the dropdown menu.
- Extract the ZIP File: Once the download is complete, locate the ZIP file on your computer (usually in your Downloads folder) and extract it. You can do this by right-clicking on the file and selecting - "Extract All" or "Extract Here."
</details>

<details>
<summary> 2. Installing Python Modules</summary>
- Open Command Line Interface:
    - On Windows, press Windows Key + R, type cmd, and press Enter.
    - On Mac, open the Terminal application from your Applications/Utilities folder.
- Navigate to the Project Directory: Use the cd command followed by the path to the extracted folder to change your current directory to the location of the downloaded code. For example: cd Downloads/project-folder.
- Install Required Modules: Type 
```
pip install -r requirements.txt
```
and press Enter. This command reads the requirements.txt file included in your project folder and installs all the necessary Python modules listed there.
</details>

<details>
<summary> 3. Setting Up an OpenAI API Key</summary>
- Create an OpenAI Account: Go to the OpenAI website and sign up for an account if you don’t already have one.
- Generate an API Key: Once logged in, navigate to the API section and follow the instructions to generate a new API key. Keep this key confidential.
- Configure Your Project: Open the project folder and locate the configuration file (it might be named something like config.py or settings.py). Open it with a text editor and replace the placeholder text with your OpenAI API key. This usually looks like OPENAI_API_KEY = "your_key_here".
</details>

<details>
<summary> 4. Running the Python Script/summary>
- Open Command Line Interface (if not already open):
- On Windows, press Windows Key + R, type cmd, and press Enter.
- On Mac, open the Terminal application from your Applications/Utilities folder.
- Navigate to Your Project Folder (if not already there): Use the cd command to change your current directory to the location of the downloaded code, if you've navigated away from it.
- Run the Script: Type python script_name.py, replacing script_name.py with the name of the Python script you need to run, and press Enter. The script will execute and perform the tasks as programmed.
</details>

### old

you will need to set up an OpenAI API key: https://platform.openai.com/api-keys, download our code from the Guanaco github repository: https://github.com/queercomputer/Guanaco, and install the required Python modules onto your computer:
pip install -r requirements.txt
Update the ‘seed_tasks.jsonl’ document to include your original 175 seed tasks, and update the ‘utils.py’ script with your secret OpenAI API key:
openai.api_key = '*************************************************'

You can now run the Python script: ‘generate_instruction.py’. The synthetic dataset will be outputted as ‘regen.json’ within the same folder.

When testing this lesson, generating a thousand additional tasks took around 1 hour and 20 minutes and cost us 50 cents. We recommend reflecting on the Guanaco synthetic dataset online or within a future lesson. However, the ‘regen.json’ file starts populating with tasks within minutes and can be viewed and reflected upon in class while it is being generated.


We built on the data generation pipeline from [self-instruct](https://github.com/yizhongw/self-instruct) and made the following modifications:

- We used `text-davinci-003` to generate the instruction data instead of `davinci`.
- We wrote a new prompt (`prompt.txt`) that explicitly gave the requirement of instruction generation to `text-davinci-003`. Note: there is a slight error in the prompt we used, and future users should incorporate the edit in <https://github.com/tatsu-lab/stanford_alpaca/pull/24>
- We adopted much more aggressive batch decoding, i.e., generating 20 instructions at once, which significantly reduced the cost of data generation.
- We simplified the data generation pipeline by discarding the difference between classification and non-classification instructions.
- We only generated a single instance for each instruction, instead of 2 to 3 instances as in [1].

This produced an instruction-following dataset with 52K examples obtained at a much lower cost (less than $500).
In a preliminary study, we also find our 52K generated data to be much more diverse than the data released by [self-instruct](https://github.com/yizhongw/self-instruct/blob/main/data/seed_tasks.jsonl).
We plot the below figure (in the style of Figure 2 in the [self-instruct paper](https://arxiv.org/abs/2212.10560) to demonstrate the diversity of our data.
The inner circle of the plot represents the root verb of the instructions, and the outer circle represents the direct objects.

[//]: # (![parse_analysis]&#40;assert/parse_analysis.png | width=100&#41;)
[<img src="assets/parse_analysis.png" width="750" />](./assets/parse_analysis.png)



### Authors

- [Joel Humphries](https://joelhumphries.glitch.me)
- [Dr Christopher O’Neill](https://www.admscentre.org.au/christopher-oneill/)


### Citations

Please cite the repo if you use the data or code in this repo.

```
@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}
```

Naturally, you should also cite the original LLaMA paper [1] and the Self-Instruct paper [2].

### Acknowledgements

We thank Yizhong Wang for his help in explaining the data generation pipeline in Self-Instruct and providing the code for the parse analysis plot.
We thank Yifan Mai for helpful support, and members of the Stanford NLP Group as well as the Center for Research on Foundation Models (CRFM) for their helpful feedback.
